<!DOCTYPE html>
<html dir="ltr" lang="en-US"><head><!-- Created by Artisteer v4.1.0.59861 -->
    <meta charset="utf-8">
    <title>Project</title>
    <meta name="viewport" content="initial-scale = 1.0, maximum-scale = 1.0, user-scalable = no, width = device-width">

    <!--[if lt IE 9]><script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
    <link rel="stylesheet" href="style.css" media="screen">
    <!--[if lte IE 7]><link rel="stylesheet" href="style.ie7.css" media="screen" /><![endif]-->
    <link rel="stylesheet" href="style.responsive.css" media="all">


    <script src="jquery.js"></script>
    <script src="script.js"></script>
    <script src="script.responsive.js"></script>


</head>
<body>
<div id="art-main">
<header class="art-header">


    <div class="art-shapes">

            </div>






</header>
<nav class="art-nav">
    <div class="art-nav-inner">
    <ul class="art-hmenu"><li><a href="short-cv.html" class="">Short Cv</a></li><li><a href="publications.html" class="">Publications</a></li><li><a href="teaching.html" class="">Teaching</a></li><li><a href="research.html" class="">Research</a></li><li><a href="projects.html" class="active">Projects</a></li></ul>
        </div>
    </nav>
<div class="art-sheet clearfix">
            <div class="art-layout-wrapper">
                <div class="art-content-layout">
                    <div class="art-content-layout-row">
                        <div class="art-layout-cell art-content"><article class="art-post art-article">
                                <div class="art-postmetadataheader">
                                        <h2 class="art-postheader">Virtual Reality - Everyday Assessment Lab (VR-EAL)</h2>
                                        <div class="art-postcontent art-postcontent-0 clearfix"><p> PhD Thesis </p></div>
								<li> A Brief Preview of the Game Mechanics of VR-EAL<br></li>
								 <video width="800" height="600" autoplay>
                                 <source src="vreal_preview.mp4" type="video/mp4">
								 </video>
								<li> The Innovative Nature of VR-EAL:  <br></li>
								<p>	VR-EAL is the first VR scenario which embeds 5 apps (Episodic Memory App, Multi-Tasking App, Selective Attention App, Divided Attention App, Sustained Attention App) in order to assess Prospective Memory which is paramount to everyday functionality. However, the embedded apps may be used independently (not within the story-line) to assess a specific cognitive ability. Hence, VR-EAL is a small library of apps. Their development is the very first step towards the establishment of significant telemedicine tools which will allow the assessment of individuals either professionals or patients at distance. Thus, the individual may have a comprehensive assessment and report without visiting a neuropsychologist and/or a physician (MD). Also, the accumulated data may facilitate the development of patient-centred rehabilitation and training programs, e.g. building an A.I. support assistant (AR app) or by providing an Error-Less Therapy program for the respective ability. Finally, the apps do not only solve major clinical problems (see below the Ecological Validity issue) but also resolves the replication crisis in Neuroscientific Research. The open source and structured design as well as the exclusion of human biases consolidate a robust and precise experimental paradigm which may easily be adapted in any language and culture.</p>
								<li> Description of VR-EAL: <br></li>
								<p> The project pertains to the completion of everyday tasks i.e. detecting items that are required to do some activities (e.g. money, keys, book, garage opener, envelope and letter, medication pills/tablets) preparing breakfast, memorising a shopping list, planning the itinerary to convenience store, detecting posters of famous singers, spotting sounds in the environment, returning a book to the library, take medication on time, post a letter, and open the garage door. The user is in a flat where he requires to perform a series of tasks, and then should continue with going to specific places (post office, bakery, library, and convenience store) to perform the aforementioned tasks.</p>
								<li> Purpose of the VR-EAL: <br></li>
								<p>	The main incentive to realise this project is to develop an ecological valid neuropsychological assessment. Neuropsychological assessments are used to appraise cognitive (brain) functions such as Attention, Memory, Executive functions (merge, differentiate, and allocate information coming from the senses like vision, hearing, touch, smell, and taste), Visuospatial Functions (visual - perceptual skills of space e.g. understanding shapes), and Social Cognition (understand intentions, emotions, moral issues, and respond accordingly to the social context). Currently, the neuropsychological assessment of the cognitive functions relies predominantly to paper-pencil tests. The issue of the paper-pencil versions or even the computerised versions (digital versions for tablets or personal computers) is that they do not depict accurately the everyday functionality of the assessed person. This is due to lack of ecological validity (In common words the neuropsychological tests do not represent the real-life abilities and tasks). For example, someone may have scored high in the paper-pencil tests but in her/his everyday interaction in real life to be impaired or failing in supposedly “easy” tasks like cooking a meal or paying something on time. Of course, the latter example may be vice versa, failing in tests but being functional in everyday activities. The failure to represent the everyday functionality of the person by using paper-pencil or computerised tests may be resolved by implementing VR neuropsychological assessment (tests). VR Platform, Industry, and target groups: VR-EAL will be a research and clinical tool for the assessment of everyday abilities (see details above). As a research and clinical tool, the target industry is the academia (e.g. universities and labs) and national health systems (e.g. hospitals, rehabilitation centres, community centres). The target groups are autistic individuals and outpatients (>1year after the incident) with brain injuries (either ABI or TBI) (or anyone with impaired daily finctionality). We require to evade any VR adverse effects and symptoms and to facilitate ergonomic movement and controls. Thus, the only option is high-end commercial HMDs like HTC Vive and Oculus Rift. Though, Vive seems to have better pick and place ergonomics as well as tracking system (lighthouse stations). </p>
								<li> Comparison to existing VR assessments: <br></li>
								<p> An advantage of the VR-EAL is that will be designed based on the capabilities of the recently dispersed high-end head mounted devices (HMDs) like HTC VIVE and Oculus Rift. The advantage, beyond offering better rendering and graphics, is the ergonomics for the interaction with and movement in the virtual environment. For example, as mentioned above, the better tracking system (e.g. lighthouse stations), the teleportation movement from one point to the other, and the wands (controllers) which enable a natural interaction like picking and placing objects, all the above facilitate an improved VR experience and alleviate the threat of experiencing nausea or other adverse VR induced symptomatology. </p>
                <p> </p>
                <p> </p>
                <div class="art-sheet clearfix">
                            <div class="art-layout-wrapper">
                                <div class="art-content-layout">
                                    <div class="art-content-layout-row">
                                        <div class="art-layout-cell art-content"><article class="art-post art-article">
                                                <div class="art-postmetadataheader">
                                                        <h2 class="art-postheader"> Other XR Projects </h2>
                <div class="art-postcontent art-postcontent-0 clearfix"><p> uCreateStudio </p></div>
                <li>VR Exchange of Data: An Immersive Virtual Environment for Exchanging Scientific & Clinical Data. <br></li>
								<p> Double Encryption (Synchronous & Asynchronous) and Steganography (In Video File) of Data, Video Display of Identification Documents, and Interactive Two-Directional Confirmation of the Prospective Exchange.
                Collaboration with Dr. Nick Pitropakis, Cybersecurity Department, Napier University of Edinburgh, UK.</p>
                <p>
                </p>
                <li> Singularity Postponed <br></li>
								<p> An Immersive Creative Experience Highlighting the Complexity of Uploading Human Cognition and Emotion on the Cloud.
                Collaboration with MA Lisa Brown, Edinburgh College of Art, University of Edinburgh, UK. </p>
                <p>
                </p>
                <li> WebVR Exhibition – Lin Huiyin <br></li>
                <p> This is an immersive exhibition of the life and work of Lin Huiyin, A well-known Chinese architect, diplomat, poetess, and writer. This VR software runs both online on Mozilla Firefox browser (WebVR Version) and on a high-end PC (standalone version).<p>
                <p> Video – WebVR Version:  <a href="https://www.youtube.com/watch?v=fJMvnU72KFM"> WATCH </a> </p>
                <p> Video – Standalone Version: <a href="https://www.youtube.com/watch?v=sAZ3mD4UY5Y&t=25s"> WATCH </a> </p>
                <p> Website: <a href="https://funnydoudou.wordpress.com/"> VISIT </a> </p>
                <p> A collaboration with MA Yiwen Zhi, Digital Humanities, University of Bologna, Italy.</p>
                <p>
                </p>
                <li> uCreate Studio VR Exhibition <br></li>
                <p> A Virtual Tour at (an imaginary - Sci-Fi) uCreate Studio, where you may see and get information about the several cutting-edge technologies that we use in the uCreate Studio, University of Edinburgh. Also, there is a bitter-sweet ecological message at the end of the tour.
                This VR software aims to promote the technologies, services, and environmental goals of uCreate Studio.<p>
                <p> Video: <a href="https://www.youtube.com/watch?v=tMbRXTj_TJQ&t=2s"> WATCH </a> <p>
                <p> A collaboration with Mike Boyd, Head of uCreate Studio, University of Edinburgh, UK. </p>
                <p>
                </p>
                <li> Data Visualisation of Fluid Dynamics <br></li>
                <p> An Immersive VR - Data Visualisation app of fluid dynamics (velocity magnitude, velocity on the 3 directional axes, and static pressure) by using Computational fluid dynamics (CFD) in Unity.
                The app has two versions (Static Data Visualisation & Transient Data Visualisation).<p>
                <p> Video – Static: <a href="https://www.youtube.com/watch?v=ZMb2e831CVk"> WATCH </a><p>
                <p> Video -Transient:<a href="https://www.youtube.com/watch?v=3QUu5Wsv9_c"> WATCH </a><p>
                <p> A collaboration with MEng Scott Towt and Professor Prash Valluri, Chemical Engineering Department, School of Engineering, University of Edinburgh, UK </p>
                <p>
                </p>
                <li> Virtual Reality Digital Watch <br></li>
                <p> A digital watch to be used in VR projects and improve the quality of the temporal illusion. <p>
                <p> Project’s Repository: <a href="https://github.com/PanosCortese/Virtual_Reality_Digital_Watch"> VISIT </a> </p>
								 </article></div>
                    </div>
                </div>
            </div>
    </div>
<footer class="art-footer">
  <div class="art-footer-inner">
<br>
<br>
<p>Copyright © 2020. Panagiotis Kourtesis&nbsp;</p><p><br></p><p><br></p><p><br></p>
<p><br></p>

  </div>
</footer>

</div>


</body></html>
