<!DOCTYPE html>
<html dir="ltr" lang="en-US"><head><!-- Created by Artisteer v4.1.0.59861 -->
    <meta charset="utf-8">
    <title>Project</title>
    <meta name="viewport" content="initial-scale = 1.0, maximum-scale = 1.0, user-scalable = no, width = device-width">

    <!--[if lt IE 9]><script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
    <link rel="stylesheet" href="style.css" media="screen">
    <!--[if lte IE 7]><link rel="stylesheet" href="style.ie7.css" media="screen" /><![endif]-->
    <link rel="stylesheet" href="style.responsive.css" media="all">


    <script src="jquery.js"></script>
    <script src="script.js"></script>
    <script src="script.responsive.js"></script>


</head>
<body>
<div id="art-main">
<header class="art-header">


    <div class="art-shapes">

            </div>






</header>
<nav class="art-nav">
    <div class="art-nav-inner">
    <ul class="art-hmenu"><li><a href="short-cv.html" class="">Short Cv</a></li><li><a href="publications.html" class="">Publications</a></li><li><a href="teaching.html" class="">Teaching</a></li><li><a href="research.html" class="">Research</a></li><li><a href="projects.html" class="active">Projects</a></li></ul>
        </div>
    </nav>
<div class="art-sheet clearfix">
            <div class="art-layout-wrapper">
                <div class="art-content-layout">
                    <div class="art-content-layout-row">
                        <div class="art-layout-cell art-content"><article class="art-post art-article">
                                <div class="art-postmetadataheader">
                                        <h2 class="art-postheader">Project</h2>

                                    </div>
                                <div class="art-postcontent art-postcontent-0 clearfix"><p>Virtual Reality - Everyday Assessment Lab (VR-EAL)</p></div>
								<li> A Brief Preview of the Game Mechanics of VR-EAL<br></li>
								 <video width="800" height="600" autoplay>
                                 <source src="vreal_preview.mp4" type="video/mp4">
								 </video>
								<li> The Innovative Nature of VR-EAL:  <br></li>
								<p>	VR-EAL is the first VR scenario which embeds 5 apps (Episodic Memory App, Multi-Tasking App, Selective Attention App, Divided Attention App, Sustained Attention App) in order to assess Prospective Memory which is paramount to everyday functionality. However, the embedded apps may be used independently (not within the story-line) to assess a specific cognitive ability. Hence, VR-EAL is a small library of apps. Their development is the very first step towards the establishment of significant telemedicine tools which will allow the assessment of individuals either professionals or patients at distance. Thus, the individual may have a comprehensive assessment and report without visiting a neuropsychologist and/or a physician (MD). Also, the accumulated data may facilitate the development of patient-centred rehabilitation and training programs, e.g. building an A.I. support assistant (AR app) or by providing an Error-Less Therapy program for the respective ability. Finally, the apps do not only solve major clinical problems (see below the Ecological Validity issue) but also resolves the replication crisis in Neuroscientific Research. The open source and structured design as well as the exclusion of human biases consolidate a robust and precise experimental paradigm which may easily be adapted in any language and culture.</p>
								<li> Description of VR-EAL: <br></li>
								<p> The project pertains to the completion of everyday tasks i.e. detecting items that are required to do some activities (e.g. money, keys, book, garage opener, envelope and letter, medication pills/tablets) preparing breakfast, memorising a shopping list, planning the itinerary to convenience store, detecting posters of famous singers, spotting sounds in the environment, returning a book to the library, take medication on time, post a letter, and open the garage door. The user is in a flat where he requires to perform a series of tasks, and then should continue with going to specific places (post office, bakery, library, and convenience store) to perform the aforementioned tasks.</p>
								<li> Purpose of the VR-EAL: <br></li>
								<p>	The main incentive to realise this project is to develop an ecological valid neuropsychological assessment. Neuropsychological assessments are used to appraise cognitive (brain) functions such as Attention, Memory, Executive functions (merge, differentiate, and allocate information coming from the senses like vision, hearing, touch, smell, and taste), Visuospatial Functions (visual - perceptual skills of space e.g. understanding shapes), and Social Cognition (understand intentions, emotions, moral issues, and respond accordingly to the social context). Currently, the neuropsychological assessment of the cognitive functions relies predominantly to paper-pencil tests. The issue of the paper-pencil versions or even the computerised versions (digital versions for tablets or personal computers) is that they do not depict accurately the everyday functionality of the assessed person. This is due to lack of ecological validity (In common words the neuropsychological tests do not represent the real-life abilities and tasks). For example, someone may have scored high in the paper-pencil tests but in her/his everyday interaction in real life to be impaired or failing in supposedly “easy” tasks like cooking a meal or paying something on time. Of course, the latter example may be vice versa, failing in tests but being functional in everyday activities. The failure to represent the everyday functionality of the person by using paper-pencil or computerised tests may be resolved by implementing VR neuropsychological assessment (tests). VR Platform, Industry, and target groups: VR-EAL will be a research and clinical tool for the assessment of everyday abilities (see details above). As a research and clinical tool, the target industry is the academia (e.g. universities and labs) and national health systems (e.g. hospitals, rehabilitation centres, community centres). The target groups are autistic individuals and outpatients (>1year after the incident) with brain injuries (either ABI or TBI) (or anyone with impaired daily finctionality). We require to evade any VR adverse effects and symptoms and to facilitate ergonomic movement and controls. Thus, the only option is high-end commercial HMDs like HTC Vive and Oculus Rift. Though, Vive seems to have better pick and place ergonomics as well as tracking system (lighthouse stations). </p>
								<li> Comparison to existing VR assessments: <br></li>
								<p> An advantage of the VR-EAL is that will be designed based on the capabilities of the recently dispersed high-end head mounted devices (HMDs) like HTC VIVE and Oculus Rift. The advantage, beyond offering better rendering and graphics, is the ergonomics for the interaction with and movement in the virtual environment. For example, as mentioned above, the better tracking system (e.g. lighthouse stations), the teleportation movement from one point to the other, and the wands (controllers) which enable a natural interaction like picking and placing objects, all the above facilitate an improved VR experience and alleviate the threat of experiencing nausea or other adverse VR induced symptomatology. </p>
								 </article></div>
                    </div>
                </div>
            </div>
    </div>
<footer class="art-footer">
  <div class="art-footer-inner">
<br>
<br>
<p>Copyright © 2020. Panagiotis Kourtesis&nbsp;</p><p><br></p><p><br></p><p><br></p>
<p><br></p>

  </div>
</footer>

</div>


</body></html>
